
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="ie=edge" http-equiv="x-ua-compatible"/>
<link href="http://mackelab.org/sbi/reference/" rel="canonical"/>
<meta content="Copy to clipboard" name="lang:clipboard.copy"/>
<meta content="Copied to clipboard" name="lang:clipboard.copied"/>
<meta content="en" name="lang:search.language"/>
<meta content="True" name="lang:search.pipeline.stopwords"/>
<meta content="True" name="lang:search.pipeline.trimmer"/>
<meta content="No matching documents" name="lang:search.result.none"/>
<meta content="1 matching document" name="lang:search.result.one"/>
<meta content="# matching documents" name="lang:search.result.other"/>
<meta content="[\s\-]+" name="lang:search.tokenizer"/>
<link href="../assets/images/favicon.png" rel="shortcut icon"/>
<meta content="mkdocs-1.1, mkdocs-material-4.6.3" name="generator"/>
<title>API Reference - sbi</title>
<link href="../assets/stylesheets/application.adb8469c.css" rel="stylesheet"/>
<link href="../assets/stylesheets/application-palette.a8b3c06d.css" rel="stylesheet"/>
<meta content="#3f51b5" name="theme-color"/>
<script src="../assets/javascripts/modernizr.86422ebf.js"></script>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&amp;display=fallback" rel="stylesheet"/>
<style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
<link href="../assets/fonts/material-icons.css" rel="stylesheet"/>
<link href="../static/global.css" rel="stylesheet"/>
<link href="../css/ansi-colours.css" rel="stylesheet"/>
<link href="../css/jupyter-cells.css" rel="stylesheet"/>
<link href="../css/pandas-dataframe.css" rel="stylesheet"/>
</head>
<body data-md-color-accent="indigo" data-md-color-primary="indigo" dir="ltr">
<svg class="md-svg">
<defs>
<svg height="448" id="__github" viewbox="0 0 416 448" width="416" xmlns="http://www.w3.org/2000/svg"><path d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z" fill="currentColor"></path></svg>
</defs>
</svg>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
<a class="md-skip" href="#api-reference" tabindex="0">
        Skip to content
      </a>
<header class="md-header" data-md-component="header">
<nav class="md-header-nav md-grid">
<div class="md-flex">
<div class="md-flex__cell md-flex__cell--shrink">
<a aria-label="sbi" class="md-header-nav__button md-logo" href="http://mackelab.org/sbi/" title="sbi">
<img alt="logo" height="24" src="../static/logo.svg" width="24"/>
</a>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
</div>
<div class="md-flex__cell md-flex__cell--stretch">
<div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
<span class="md-header-nav__topic">
              sbi
            </span>
<span class="md-header-nav__topic">
              
                API Reference
              
            </span>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="query" data-md-state="active" name="query" placeholder="Search" spellcheck="false" type="text"/>
<label class="md-icon md-search__icon" for="__search"></label>
<button class="md-icon md-search__icon" data-md-component="reset" tabindex="-1" type="reset">
        Óóç
      </button>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="result">
<div class="md-search-result__meta">
            Type to start searching
          </div>
<ol class="md-search-result__list"></ol>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<div class="md-header-nav__source">
<a class="md-source" data-md-source="github" href="http://github.com/mackelab/sbi/" title="Go to repository">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    mackelab/sbi
  </div>
</a>
</div>
</div>
</div>
</nav>
</header>
<div class="md-container">
<main class="md-main" role="main">
<div class="md-main__inner md-grid" data-md-component="container">
<div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title md-nav__title--site" for="__drawer">
<a class="md-nav__button md-logo" href="http://mackelab.org/sbi/" title="sbi">
<img alt="logo" height="48" src="../static/logo.svg" width="48"/>
</a>
    sbi
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-source="github" href="http://github.com/mackelab/sbi/" title="Go to repository">
<div class="md-source__icon">
<svg height="24" viewbox="0 0 24 24" width="24">
<use height="24" width="24" xlink:href="#__github"></use>
</svg>
</div>
<div class="md-source__repository">
    mackelab/sbi
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href=".." title="Home">
      Home
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../install/" title="Installation">
      Installation
    </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-toggle md-nav__toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
        API Reference
      </label>
<a class="md-nav__link md-nav__link--active" href="./" title="API Reference">
      API Reference
    </a>
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">Table of contents</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference">
    Inference
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snpe.snpe_a.SnpeA">
    SnpeA
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snpe.snpe_b.SnpeB">
    SnpeB
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snpe.snpe_c.SnpeC">
    SnpeC
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snl.snl.SNL">
    SNL
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.sre.sre.SRE">
    SRE
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#models">
    Models
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.utils.get_nn_models.posterior_nn">
    posterior_nn()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.utils.get_nn_models.likelihood_nn">
    likelihood_nn()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.utils.get_nn_models.classifier_nn">
    classifier_nn()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../credits/" title="Credits">
      Credits
    </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">Table of contents</label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#inference">
    Inference
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snpe.snpe_a.SnpeA">
    SnpeA
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snpe.snpe_b.SnpeB">
    SnpeB
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snpe.snpe_c.SnpeC">
    SnpeC
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.snl.snl.SNL">
    SNL
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.inference.sre.sre.SRE">
    SRE
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#models">
    Models
  </a>
<nav class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.utils.get_nn_models.posterior_nn">
    posterior_nn()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.utils.get_nn_models.likelihood_nn">
    likelihood_nn()
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#sbi.utils.get_nn_models.classifier_nn">
    classifier_nn()
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content">
<article class="md-content__inner md-typeset">
<a class="md-icon md-content__icon" href="http://github.com/mackelab/sbi/edit/master/docs/reference.md" title="Edit this page">Óèâ</a>
<h1 id="api-reference">API Reference<a class="headerlink" href="#api-reference" title="Permanent link">¬∂</a></h1>
<h2 id="inference">Inference<a class="headerlink" href="#inference" title="Permanent link">¬∂</a></h2>
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="sbi.inference.snpe.snpe_a.SnpeA">
<code>sbi.inference.snpe.snpe_a.SnpeA</code>
<a class="headerlink" href="#sbi.inference.snpe.snpe_a.SnpeA" title="Permanent link">¬∂</a></h3>
<div class="doc doc-contents first">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" data-toc-label="__init__()" id="sbi.inference.snpe.snpe_a.SnpeA.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">simulator</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">true_observation</span><span class="p">,</span> <span class="n">num_pilot_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">density_estimator</span><span class="o">=</span><span class="s1">'maf'</span><span class="p">,</span> <span class="n">use_combined_loss</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">z_score_obs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">simulation_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">discard_prior_samples</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">summary_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h4>
<div class="doc doc-contents">
<p>SNPE-A</p>
<p>Implementation of <em>Fast epsilon-free Inference of Simulation Models with Bayesian Conditional Density Estimation</em> by Papamakarios et al., NeurIPS 2016, 
<a href="https://arxiv.org/abs/1605.06376">https://arxiv.org/abs/1605.06376</a></p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>num_pilot_samples</code></td>
<td><code></code></td>
<td>
<p>number of simulations that are run when instantiating an object. Used to z-score the observations.</p>
</td>
<td><code>100</code></td>
</tr>
<tr>
<td><code>density_estimator</code></td>
<td><code></code></td>
<td>
<p>neural density estimator</p>
</td>
<td><code>'maf'</code></td>
</tr>
<tr>
<td><code>calibration_kernel</code></td>
<td><code></code></td>
<td>
<p>a function to calibrate the context</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>z_score_obs</code></td>
<td><code></code></td>
<td>
<p>whether to z-score the data features x</p>
</td>
<td><code>True</code></td>
</tr>
<tr>
<td><code>use_combined_loss</code></td>
<td><code></code></td>
<td>
<p>whether to jointly neural_net prior samples  using maximum likelihood. Useful to prevent density leaking when using box uniform priors.</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>retrain_from_scratch_each_round</code></td>
<td><code></code></td>
<td>
<p>whether to retrain the conditional density estimator for the posterior from scratch each round.</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>discard_prior_samples</code></td>
<td><code></code></td>
<td>
<p>whether to discard prior samples from round two onwards.</p>
</td>
<td><code>False</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>sbi/inference/snpe/snpe_a.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">simulator</span><span class="p">,</span>
    <span class="n">prior</span><span class="p">,</span>
    <span class="n">true_observation</span><span class="p">,</span>
    <span class="n">num_pilot_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">density_estimator</span><span class="o">=</span><span class="s2">"maf"</span><span class="p">,</span>
    <span class="n">use_combined_loss</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">z_score_obs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">simulation_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">discard_prior_samples</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">summary_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">"""SNPE-A</span>

<span class="sd">    Implementation of _Fast epsilon-free Inference of Simulation Models with Bayesian Conditional Density Estimation_ by Papamakarios et al., NeurIPS 2016, </span>
<span class="sd">    https://arxiv.org/abs/1605.06376</span>

<span class="sd">    Args:</span>
<span class="sd">        num_pilot_samples: number of simulations that are run when</span>
<span class="sd">            instantiating an object. Used to z-score the observations.   </span>
<span class="sd">        density_estimator: neural density estimator</span>
<span class="sd">        calibration_kernel: a function to calibrate the context</span>
<span class="sd">        z_score_obs: whether to z-score the data features x</span>
<span class="sd">        use_combined_loss: whether to jointly neural_net prior samples </span>
<span class="sd">            using maximum likelihood. Useful to prevent density leaking when using box uniform priors.</span>
<span class="sd">        retrain_from_scratch_each_round: whether to retrain the conditional</span>
<span class="sd">            density estimator for the posterior from scratch each round.</span>
<span class="sd">        discard_prior_samples: whether to discard prior samples from round</span>
<span class="sd">            two onwards.</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">SnpeA</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">,</span>
        <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span>
        <span class="n">true_observation</span><span class="o">=</span><span class="n">true_observation</span><span class="p">,</span>
        <span class="n">num_pilot_samples</span><span class="o">=</span><span class="n">num_pilot_samples</span><span class="p">,</span>
        <span class="n">density_estimator</span><span class="o">=</span><span class="n">density_estimator</span><span class="p">,</span>
        <span class="n">use_combined_loss</span><span class="o">=</span><span class="n">use_combined_loss</span><span class="p">,</span>
        <span class="n">z_score_obs</span><span class="o">=</span><span class="n">z_score_obs</span><span class="p">,</span>
        <span class="n">simulation_batch_size</span><span class="o">=</span><span class="n">simulation_batch_size</span><span class="p">,</span>
        <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="n">retrain_from_scratch_each_round</span><span class="p">,</span>
        <span class="n">discard_prior_samples</span><span class="o">=</span><span class="n">discard_prior_samples</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="sbi.inference.snpe.snpe_b.SnpeB">
<code>sbi.inference.snpe.snpe_b.SnpeB</code>
<a class="headerlink" href="#sbi.inference.snpe.snpe_b.SnpeB" title="Permanent link">¬∂</a></h3>
<div class="doc doc-contents first">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" data-toc-label="__init__()" id="sbi.inference.snpe.snpe_b.SnpeB.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">simulator</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">true_observation</span><span class="p">,</span> <span class="n">num_pilot_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">density_estimator</span><span class="o">=</span><span class="s1">'maf'</span><span class="p">,</span> <span class="n">calibration_kernel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_combined_loss</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">z_score_obs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">simulation_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">discard_prior_samples</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">summary_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h4>
<div class="doc doc-contents">
<p>Implementation of <strong>Flexible statistical inference for mechanistic models of neural dynamics</strong> by Lueckmann et al., NeurIPS 2017, <a href="https://arxiv.org/abs/1711.01861">https://arxiv.org/abs/1711.01861</a></p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>num_pilot_samples</code></td>
<td><code></code></td>
<td>
<p>number of simulations that are run when instantiating an object. Used to z-score the observations.</p>
</td>
<td><code>100</code></td>
</tr>
<tr>
<td><code>density_estimator</code></td>
<td><code></code></td>
<td>
<p>neural density estimator</p>
</td>
<td><code>'maf'</code></td>
</tr>
<tr>
<td><code>calibration_kernel</code></td>
<td><code></code></td>
<td>
<p>a function to calibrate the context</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>z_score_obs</code></td>
<td><code></code></td>
<td>
<p>whether to z-score the data features x</p>
</td>
<td><code>True</code></td>
</tr>
<tr>
<td><code>use_combined_loss</code></td>
<td><code></code></td>
<td>
<p>whether to jointly neural_net prior samples  using maximum likelihood. Useful to prevent density leaking when using box uniform priors.</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>retrain_from_scratch_each_round</code></td>
<td><code></code></td>
<td>
<p>whether to retrain the conditional density estimator for the posterior from scratch each round.</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>discard_prior_samples</code></td>
<td><code></code></td>
<td>
<p>whether to discard prior samples from round two onwards.</p>
</td>
<td><code>False</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>sbi/inference/snpe/snpe_b.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">simulator</span><span class="p">,</span>
    <span class="n">prior</span><span class="p">,</span>
    <span class="n">true_observation</span><span class="p">,</span>
    <span class="n">num_pilot_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">density_estimator</span><span class="o">=</span><span class="s2">"maf"</span><span class="p">,</span>
    <span class="n">calibration_kernel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">use_combined_loss</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">z_score_obs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">simulation_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">discard_prior_samples</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">summary_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">"""</span>

<span class="sd">    Implementation of __Flexible statistical inference for mechanistic models of neural dynamics__ by Lueckmann et al., NeurIPS 2017, https://arxiv.org/abs/1711.01861</span>

<span class="sd">    Args:</span>
<span class="sd">        num_pilot_samples: number of simulations that are run when</span>
<span class="sd">            instantiating an object. Used to z-score the observations.   </span>
<span class="sd">        density_estimator: neural density estimator</span>
<span class="sd">        calibration_kernel: a function to calibrate the context</span>
<span class="sd">        z_score_obs: whether to z-score the data features x</span>
<span class="sd">        use_combined_loss: whether to jointly neural_net prior samples </span>
<span class="sd">            using maximum likelihood. Useful to prevent density leaking when using box uniform priors.</span>
<span class="sd">        retrain_from_scratch_each_round: whether to retrain the conditional</span>
<span class="sd">            density estimator for the posterior from scratch each round.</span>
<span class="sd">        discard_prior_samples: whether to discard prior samples from round</span>
<span class="sd">            two onwards.</span>
<span class="sd">    """</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">SnpeB</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">,</span>
        <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span>
        <span class="n">true_observation</span><span class="o">=</span><span class="n">true_observation</span><span class="p">,</span>
        <span class="n">num_pilot_samples</span><span class="o">=</span><span class="n">num_pilot_samples</span><span class="p">,</span>
        <span class="n">density_estimator</span><span class="o">=</span><span class="n">density_estimator</span><span class="p">,</span>
        <span class="n">calibration_kernel</span><span class="o">=</span><span class="n">calibration_kernel</span><span class="p">,</span>
        <span class="n">use_combined_loss</span><span class="o">=</span><span class="n">use_combined_loss</span><span class="p">,</span>
        <span class="n">z_score_obs</span><span class="o">=</span><span class="n">z_score_obs</span><span class="p">,</span>
        <span class="n">simulation_batch_size</span><span class="o">=</span><span class="n">simulation_batch_size</span><span class="p">,</span>
        <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="n">retrain_from_scratch_each_round</span><span class="p">,</span>
        <span class="n">discard_prior_samples</span><span class="o">=</span><span class="n">discard_prior_samples</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="sbi.inference.snpe.snpe_c.SnpeC">
<code>sbi.inference.snpe.snpe_c.SnpeC</code>
<a class="headerlink" href="#sbi.inference.snpe.snpe_c.SnpeC" title="Permanent link">¬∂</a></h3>
<div class="doc doc-contents first">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" data-toc-label="__init__()" id="sbi.inference.snpe.snpe_c.SnpeC.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">simulator</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">true_observation</span><span class="p">,</span> <span class="n">num_atoms</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_pilot_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">density_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">calibration_kernel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_combined_loss</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">z_score_obs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">simulation_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">discard_prior_samples</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">summary_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_with_mcmc</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mcmc_method</span><span class="o">=</span><span class="s1">'slice-np'</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h4>
<div class="doc doc-contents">
<p>SNPE-C / APT</p>
<p>Implementation of <em>Automatic Posterior Transformation for Likelihood-free
Inference</em> by Greenberg et al., ICML 2019, <a href="https://arxiv.org/abs/1905.07488">https://arxiv.org/abs/1905.07488</a></p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>num_pilot_samples</code></td>
<td><code></code></td>
<td>
<p>number of simulations that are run when instantiating an object. Used to z-score the observations.</p>
</td>
<td><code>100</code></td>
</tr>
<tr>
<td><code>density_estimator</code></td>
<td><code></code></td>
<td>
<p>neural density estimator</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>calibration_kernel</code></td>
<td><code></code></td>
<td>
<p>a function to calibrate the context</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>z_score_obs</code></td>
<td><code></code></td>
<td>
<p>whether to z-score the data features x</p>
</td>
<td><code>True</code></td>
</tr>
<tr>
<td><code>use_combined_loss</code></td>
<td><code></code></td>
<td>
<p>whether to jointly neural_net prior samples  using maximum likelihood. Useful to prevent density leaking when using box uniform priors.</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>retrain_from_scratch_each_round</code></td>
<td><code></code></td>
<td>
<p>whether to retrain the conditional density estimator for the posterior from scratch each round.</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>discard_prior_samples</code></td>
<td><code></code></td>
<td>
<p>whether to discard prior samples from round two onwards.</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>num_atoms</code></td>
<td><code></code></td>
<td>
<p>int Number of atoms to use for classification. If -1, use all other parameters in minibatch.</p>
</td>
<td><code>-1</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>sbi/inference/snpe/snpe_c.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">simulator</span><span class="p">,</span>
    <span class="n">prior</span><span class="p">,</span>
    <span class="n">true_observation</span><span class="p">,</span>
    <span class="n">num_atoms</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">num_pilot_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">density_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">calibration_kernel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">use_combined_loss</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">z_score_obs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">simulation_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">discard_prior_samples</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">summary_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_with_mcmc</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">mcmc_method</span><span class="o">=</span><span class="s2">"slice-np"</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">"""SNPE-C / APT</span>

<span class="sd">    Implementation of _Automatic Posterior Transformation for Likelihood-free</span>
<span class="sd">    Inference_ by Greenberg et al., ICML 2019, https://arxiv.org/abs/1905.07488</span>

<span class="sd">    Args:</span>
<span class="sd">        num_pilot_samples: number of simulations that are run when</span>
<span class="sd">            instantiating an object. Used to z-score the observations.   </span>
<span class="sd">        density_estimator: neural density estimator</span>
<span class="sd">        calibration_kernel: a function to calibrate the context</span>
<span class="sd">        z_score_obs: whether to z-score the data features x</span>
<span class="sd">        use_combined_loss: whether to jointly neural_net prior samples </span>
<span class="sd">            using maximum likelihood. Useful to prevent density leaking when using box uniform priors.</span>
<span class="sd">        retrain_from_scratch_each_round: whether to retrain the conditional</span>
<span class="sd">            density estimator for the posterior from scratch each round.</span>
<span class="sd">        discard_prior_samples: whether to discard prior samples from round</span>
<span class="sd">            two onwards.</span>
<span class="sd">        num_atoms: int</span>
<span class="sd">            Number of atoms to use for classification.</span>
<span class="sd">            If -1, use all other parameters in minibatch.</span>
<span class="sd">    """</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">SnpeC</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">,</span>
        <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span>
        <span class="n">true_observation</span><span class="o">=</span><span class="n">true_observation</span><span class="p">,</span>
        <span class="n">num_pilot_samples</span><span class="o">=</span><span class="n">num_pilot_samples</span><span class="p">,</span>
        <span class="n">density_estimator</span><span class="o">=</span><span class="n">density_estimator</span><span class="p">,</span>
        <span class="n">calibration_kernel</span><span class="o">=</span><span class="n">calibration_kernel</span><span class="p">,</span>
        <span class="n">use_combined_loss</span><span class="o">=</span><span class="n">use_combined_loss</span><span class="p">,</span>
        <span class="n">z_score_obs</span><span class="o">=</span><span class="n">z_score_obs</span><span class="p">,</span>
        <span class="n">simulation_batch_size</span><span class="o">=</span><span class="n">simulation_batch_size</span><span class="p">,</span>
        <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="n">retrain_from_scratch_each_round</span><span class="p">,</span>
        <span class="n">discard_prior_samples</span><span class="o">=</span><span class="n">discard_prior_samples</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="n">sample_with_mcmc</span><span class="o">=</span><span class="n">sample_with_mcmc</span><span class="p">,</span>
        <span class="n">mcmc_method</span><span class="o">=</span><span class="n">mcmc_method</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_atoms</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span> <span class="s2">"Number of atoms must be an integer."</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_num_atoms</span> <span class="o">=</span> <span class="n">num_atoms</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="sbi.inference.snl.snl.SNL">
<code>sbi.inference.snl.snl.SNL</code>
<a class="headerlink" href="#sbi.inference.snl.snl.SNL" title="Permanent link">¬∂</a></h3>
<div class="doc doc-contents first">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" data-toc-label="__call__()" id="sbi.inference.snl.snl.SNL.__call__">
<code class="highlight language-python">
__call__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_rounds</span><span class="p">,</span> <span class="n">num_simulations_per_round</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">,</span> <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">stop_after_epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h4>
<div class="doc doc-contents">
<p>Run SNL</p>
<p>This runs SNL for num_rounds rounds, using num_simulations_per_round calls to
the simulator</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>num_rounds</code></td>
<td><code>int</code></td>
<td>
<p>Number of rounds to run</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>num_simulations_per_round</code></td>
<td><code>Union[List[int], int]</code></td>
<td>
<p>Number of simulator calls per round</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>batch_size</code></td>
<td><code>int</code></td>
<td>
<p>Size of batch to use for training.</p>
</td>
<td><code>100</code></td>
</tr>
<tr>
<td><code>learning_rate</code></td>
<td><code>float</code></td>
<td>
<p>Learning rate for Adam optimizer.</p>
</td>
<td><code>0.0005</code></td>
</tr>
<tr>
<td><code>validation_fraction</code></td>
<td><code>float</code></td>
<td>
<p>The fraction of data to use for validation.</p>
</td>
<td><code>0.1</code></td>
</tr>
<tr>
<td><code>stop_after_epochs</code></td>
<td><code>int</code></td>
<td>
<p>The number of epochs to wait for improvement on the validation set before terminating training.</p>
</td>
<td><code>20</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Posterior</code></td>
<td>
<p>Posterior that can be sampled and evaluated</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>sbi/inference/snl/snl.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">num_rounds</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_simulations_per_round</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5e-4</span><span class="p">,</span>
    <span class="n">validation_fraction</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="n">stop_after_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Posterior</span><span class="p">:</span>
    <span class="sd">"""Run SNL</span>

<span class="sd">    This runs SNL for num_rounds rounds, using num_simulations_per_round calls to</span>
<span class="sd">    the simulator</span>

<span class="sd">    Args:</span>
<span class="sd">        num_rounds: Number of rounds to run</span>
<span class="sd">        num_simulations_per_round: Number of simulator calls per round</span>
<span class="sd">        batch_size: Size of batch to use for training.</span>
<span class="sd">        learning_rate: Learning rate for Adam optimizer.</span>
<span class="sd">        validation_fraction: The fraction of data to use for validation.</span>
<span class="sd">        stop_after_epochs: The number of epochs to wait for improvement on the</span>
<span class="sd">            validation set before terminating training.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Posterior that can be sampled and evaluated</span>
<span class="sd">    """</span>
    <span class="n">round_description</span> <span class="o">=</span> <span class="s2">""</span>
    <span class="n">tbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_rounds</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">round_</span> <span class="ow">in</span> <span class="n">tbar</span><span class="p">:</span>

        <span class="n">tbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="n">round_description</span><span class="p">)</span>

        <span class="c1"># Generate parameters from prior in first round, and from most recent posterior</span>
        <span class="c1"># estimate in subsequent rounds.</span>
        <span class="k">if</span> <span class="n">round_</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">parameters</span><span class="p">,</span> <span class="n">observations</span> <span class="o">=</span> <span class="n">simulators</span><span class="o">.</span><span class="n">simulate_in_batches</span><span class="p">(</span>
                <span class="n">simulator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_simulator</span><span class="p">,</span>
                <span class="n">parameter_sample_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">num_samples</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prior</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">num_samples</span><span class="p">,)</span>
                <span class="p">),</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="n">num_simulations_per_round</span><span class="p">,</span>
                <span class="n">simulation_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_simulation_batch_size</span><span class="p">,</span>
                <span class="n">x_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_true_observation</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>  <span class="c1"># do not pass batch_dim</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">parameters</span><span class="p">,</span> <span class="n">observations</span> <span class="o">=</span> <span class="n">simulators</span><span class="o">.</span><span class="n">simulate_in_batches</span><span class="p">(</span>
                <span class="n">simulator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_simulator</span><span class="p">,</span>
                <span class="n">parameter_sample_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">num_samples</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neural_posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
                    <span class="n">num_samples</span>
                <span class="p">),</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="n">num_simulations_per_round</span><span class="p">,</span>
                <span class="n">simulation_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_simulation_batch_size</span><span class="p">,</span>
                <span class="n">x_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_true_observation</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>  <span class="c1"># do not pass batch_dim</span>
            <span class="p">)</span>

        <span class="c1"># Store (parameter, observation) pairs.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_parameter_bank</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">parameters</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_observation_bank</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">observations</span><span class="p">))</span>

        <span class="c1"># Fit neural likelihood to newly aggregated dataset.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">validation_fraction</span><span class="o">=</span><span class="n">validation_fraction</span><span class="p">,</span>
            <span class="n">stop_after_epochs</span><span class="o">=</span><span class="n">stop_after_epochs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Update description for progress bar.</span>
        <span class="n">round_description</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">"-------------------------</span><span class="se">\n</span><span class="s2">"</span>
            <span class="sa">f</span><span class="s2">"||||| ROUND </span><span class="si">{</span><span class="n">round_</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2"> STATS |||||:</span><span class="se">\n</span><span class="s2">"</span>
            <span class="sa">f</span><span class="s2">"-------------------------</span><span class="se">\n</span><span class="s2">"</span>
            <span class="sa">f</span><span class="s2">"Epochs trained: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_summary</span><span class="p">[</span><span class="s1">'epochs'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span>
            <span class="sa">f</span><span class="s2">"Best validation performance: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_summary</span><span class="p">[</span><span class="s1">'best_validation_log_probs'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">"</span>
        <span class="p">)</span>

        <span class="c1"># Update TensorBoard and summary dict.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_summary_writer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_summary</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">summarize</span><span class="p">(</span>
            <span class="n">summary_writer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_summary_writer</span><span class="p">,</span>
            <span class="n">summary</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_summary</span><span class="p">,</span>
            <span class="n">round_</span><span class="o">=</span><span class="n">round_</span><span class="p">,</span>
            <span class="n">true_observation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_true_observation</span><span class="p">,</span>
            <span class="n">parameter_bank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_parameter_bank</span><span class="p">,</span>
            <span class="n">observation_bank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_observation_bank</span><span class="p">,</span>
            <span class="n">simulator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_simulator</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_neural_posterior</span><span class="o">.</span><span class="n">_num_trained_rounds</span> <span class="o">=</span> <span class="n">num_rounds</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neural_posterior</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" data-toc-label="__init__()" id="sbi.inference.snl.snl.SNL.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">simulator</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">true_observation</span><span class="p">,</span> <span class="n">density_estimator</span><span class="p">,</span> <span class="n">simulation_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">summary_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mcmc_method</span><span class="o">=</span><span class="s1">'slice-np'</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h4>
<div class="doc doc-contents">
<p>Sequential Neural Likelihood</p>
<p>Implementation of
<em>Sequential Neural Likelihood: Fast Likelihood-free Inference with Autoregressive Flows</em> by Papamakarios et al., AISTATS 2019, <a href="https://arxiv.org/abs/1805.07226">https://arxiv.org/abs/1805.07226</a></p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>density_estimator</code></td>
<td><code>Optional[nn.Module]</code></td>
<td>
<p>Conditional density estimator <span><span class="MathJax_Preview">q(x|\theta)</span><script type="math/tex">q(x|\theta)</script></span>, a nn.Module with <code class="codehilite"><span class="err">log_prob</span></code> and <code class="codehilite"><span class="err">sample</span></code> methods</p>
</td>
<td><em>required</em></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>sbi/inference/snl/snl.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">simulator</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">prior</span><span class="p">,</span>
    <span class="n">true_observation</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">density_estimator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">],</span>
    <span class="n">simulation_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">summary_writer</span><span class="p">:</span> <span class="n">SummaryWriter</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mcmc_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"slice-np"</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sa">r</span><span class="sd">"""Sequential Neural Likelihood</span>

<span class="sd">    Implementation of</span>
<span class="sd">    _Sequential Neural Likelihood: Fast Likelihood-free Inference with Autoregressive Flows_ by Papamakarios et al., AISTATS 2019, https://arxiv.org/abs/1805.07226</span>

<span class="sd">    Args:</span>
<span class="sd">        density_estimator: Conditional density estimator $q(x|\theta)$, a nn.Module with `log_prob` and `sample` methods</span>
<span class="sd">    """</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">simulator</span><span class="p">,</span>
        <span class="n">prior</span><span class="p">,</span>
        <span class="n">true_observation</span><span class="p">,</span>
        <span class="n">simulation_batch_size</span><span class="p">,</span>
        <span class="n">device</span><span class="p">,</span>
        <span class="n">summary_writer</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">density_estimator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">density_estimator</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">likelihood_nn</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="s2">"maf"</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_prior</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_true_observation</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># create neural posterior which can sample()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_neural_posterior</span> <span class="o">=</span> <span class="n">Posterior</span><span class="p">(</span>
        <span class="n">algorithm_family</span><span class="o">=</span><span class="s2">"snl"</span><span class="p">,</span>
        <span class="n">neural_net</span><span class="o">=</span><span class="n">density_estimator</span><span class="p">,</span>
        <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span>
        <span class="n">context</span><span class="o">=</span><span class="n">true_observation</span><span class="p">,</span>
        <span class="n">mcmc_method</span><span class="o">=</span><span class="n">mcmc_method</span><span class="p">,</span>
        <span class="n">get_potential_function</span><span class="o">=</span><span class="n">PotentialFunctionProvider</span><span class="p">(),</span>
    <span class="p">)</span>

    <span class="c1"># XXX why not density_estimator.train(True)???</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_neural_posterior</span><span class="o">.</span><span class="n">neural_net</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># SNL-specific summary_writer fields</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_summary</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">"mcmc_times"</span><span class="p">:</span> <span class="p">[]})</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h3 class="doc doc-heading" id="sbi.inference.sre.sre.SRE">
<code>sbi.inference.sre.sre.SRE</code>
<a class="headerlink" href="#sbi.inference.sre.sre.SRE" title="Permanent link">¬∂</a></h3>
<div class="doc doc-contents first">
<div class="doc doc-children">
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" data-toc-label="__call__()" id="sbi.inference.sre.sre.SRE.__call__">
<code class="highlight language-python">
__call__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_rounds</span><span class="p">,</span> <span class="n">num_simulations_per_round</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0005</span><span class="p">,</span> <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">stop_after_epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h4>
<div class="doc doc-contents">
<p>Run SRE</p>
<p>This runs SRE for num_rounds rounds, using num_simulations_per_round calls to
the simulator</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>num_rounds</code></td>
<td><code>int</code></td>
<td>
<p>Number of rounds to run</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>num_simulations_per_round</code></td>
<td><code>Union[List[int], int]</code></td>
<td>
<p>Number of simulator calls per round</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>batch_size</code></td>
<td><code>int</code></td>
<td>
<p>Size of batch to use for training.</p>
</td>
<td><code>100</code></td>
</tr>
<tr>
<td><code>learning_rate</code></td>
<td><code>float</code></td>
<td>
<p>Learning rate for Adam optimizer.</p>
</td>
<td><code>0.0005</code></td>
</tr>
<tr>
<td><code>validation_fraction</code></td>
<td><code>float</code></td>
<td>
<p>The fraction of data to use for validation.</p>
</td>
<td><code>0.1</code></td>
</tr>
<tr>
<td><code>stop_after_epochs</code></td>
<td><code>int</code></td>
<td>
<p>The number of epochs to wait for improvement on the validation set before terminating training.</p>
</td>
<td><code>20</code></td>
</tr>
</tbody>
</table>
<p>Returns: 
    Posterior that can be sampled and evaluated.</p>
<details class="quote">
<summary>Source code in <code>sbi/inference/sre/sre.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">num_rounds</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_simulations_per_round</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5e-4</span><span class="p">,</span>
    <span class="n">validation_fraction</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="n">stop_after_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Posterior</span><span class="p">:</span>
    <span class="sd">"""Run SRE</span>

<span class="sd">    This runs SRE for num_rounds rounds, using num_simulations_per_round calls to</span>
<span class="sd">    the simulator</span>

<span class="sd">    Args:</span>
<span class="sd">        num_rounds: Number of rounds to run</span>
<span class="sd">        num_simulations_per_round: Number of simulator calls per round</span>
<span class="sd">        batch_size: Size of batch to use for training.</span>
<span class="sd">        learning_rate: Learning rate for Adam optimizer.</span>
<span class="sd">        validation_fraction: The fraction of data to use for validation.</span>
<span class="sd">        stop_after_epochs: The number of epochs to wait for improvement on the</span>
<span class="sd">            validation set before terminating training.</span>

<span class="sd">    Returns: </span>
<span class="sd">        Posterior that can be sampled and evaluated.</span>
<span class="sd">    """</span>
    <span class="n">round_description</span> <span class="o">=</span> <span class="s2">""</span>
    <span class="n">tbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_rounds</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">round_</span> <span class="ow">in</span> <span class="n">tbar</span><span class="p">:</span>

        <span class="n">tbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="n">round_description</span><span class="p">)</span>

        <span class="c1"># Generate parameters from prior in first round, and from most recent posterior</span>
        <span class="c1"># estimate in subsequent rounds.</span>
        <span class="k">if</span> <span class="n">round_</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">parameters</span><span class="p">,</span> <span class="n">observations</span> <span class="o">=</span> <span class="n">simulators</span><span class="o">.</span><span class="n">simulate_in_batches</span><span class="p">(</span>
                <span class="n">simulator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_simulator</span><span class="p">,</span>
                <span class="n">parameter_sample_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">num_samples</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prior</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">num_samples</span><span class="p">,)</span>
                <span class="p">),</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="n">num_simulations_per_round</span><span class="p">,</span>
                <span class="n">simulation_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_simulation_batch_size</span><span class="p">,</span>
                <span class="n">x_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_true_observation</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>  <span class="c1"># do not pass batch_dim</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">parameters</span><span class="p">,</span> <span class="n">observations</span> <span class="o">=</span> <span class="n">simulators</span><span class="o">.</span><span class="n">simulate_in_batches</span><span class="p">(</span>
                <span class="n">simulator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_simulator</span><span class="p">,</span>
                <span class="n">parameter_sample_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">num_samples</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neural_posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span>
                    <span class="n">num_samples</span>
                <span class="p">),</span>
                <span class="n">num_samples</span><span class="o">=</span><span class="n">num_simulations_per_round</span><span class="p">,</span>
                <span class="n">simulation_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_simulation_batch_size</span><span class="p">,</span>
                <span class="n">x_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_true_observation</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span>  <span class="c1"># do not pass batch_dim</span>
            <span class="p">)</span>

        <span class="c1"># Store (parameter, observation) pairs.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_parameter_bank</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">parameters</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_observation_bank</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">observations</span><span class="p">))</span>

        <span class="c1"># Fit posterior using newly aggregated data set.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train</span><span class="p">(</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">validation_fraction</span><span class="o">=</span><span class="n">validation_fraction</span><span class="p">,</span>
            <span class="n">stop_after_epochs</span><span class="o">=</span><span class="n">stop_after_epochs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Update description for progress bar.</span>
        <span class="n">round_description</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">"-------------------------</span><span class="se">\n</span><span class="s2">"</span>
            <span class="sa">f</span><span class="s2">"||||| ROUND </span><span class="si">{</span><span class="n">round_</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2"> STATS |||||:</span><span class="se">\n</span><span class="s2">"</span>
            <span class="sa">f</span><span class="s2">"-------------------------</span><span class="se">\n</span><span class="s2">"</span>
            <span class="sa">f</span><span class="s2">"Epochs trained: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_summary</span><span class="p">[</span><span class="s1">'epochs'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span>
            <span class="sa">f</span><span class="s2">"Best validation performance: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_summary</span><span class="p">[</span><span class="s1">'best_validation_log_probs'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">"</span>
        <span class="p">)</span>

        <span class="c1"># Update tensorboard and summary dict.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_summary_writer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_summary</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">summarize</span><span class="p">(</span>
            <span class="n">summary_writer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_summary_writer</span><span class="p">,</span>
            <span class="n">summary</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_summary</span><span class="p">,</span>
            <span class="n">round_</span><span class="o">=</span><span class="n">round_</span><span class="p">,</span>
            <span class="n">true_observation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_true_observation</span><span class="p">,</span>
            <span class="n">parameter_bank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_parameter_bank</span><span class="p">,</span>
            <span class="n">observation_bank</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_observation_bank</span><span class="p">,</span>
            <span class="n">simulator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_simulator</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_neural_posterior</span><span class="o">.</span><span class="n">_num_trained_rounds</span> <span class="o">=</span> <span class="n">num_rounds</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neural_posterior</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-method">
<h4 class="doc doc-heading" data-toc-label="__init__()" id="sbi.inference.sre.sre.SRE.__init__">
<code class="highlight language-python">
__init__<span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">simulator</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">true_observation</span><span class="p">,</span> <span class="n">classifier</span><span class="p">,</span> <span class="n">num_atoms</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">simulation_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mcmc_method</span><span class="o">=</span><span class="s1">'slice-np'</span><span class="p">,</span> <span class="n">summary_net</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">classifier_loss</span><span class="o">=</span><span class="s1">'sre'</span><span class="p">,</span> <span class="n">retrain_from_scratch_each_round</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">summary_writer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> </code>
<span class="doc doc-properties">
<small class="doc doc-property doc-property-special"><code>special</code></small>
</span>
</h4>
<div class="doc doc-contents">
<p>Sequential Ratio Estimation</p>
<p>As presented in <em>Likelihood-free MCMC with Amortized Approximate Likelihood Ratios</em> by Hermans et al., Pre-print 2019, <a href="https://arxiv.org/abs/1903.04057">https://arxiv.org/abs/1903.04057</a></p>
<p>See NeuralInference docstring for all other arguments.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>classifier</code></td>
<td><code>nn.Module</code></td>
<td>
<p>Binary classifier</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>num_atoms</code></td>
<td><code>int</code></td>
<td>
<p>Number of atoms to use for classification. If -1, use all other parameters in minibatch</p>
</td>
<td><code>-1</code></td>
</tr>
<tr>
<td><code>retrain_from_scratch_each_round</code></td>
<td><code>bool</code></td>
<td>
<p>whether to retrain from scratch each round</p>
</td>
<td><code>False</code></td>
</tr>
<tr>
<td><code>summary_net</code></td>
<td><code>Optional[nn.Module]</code></td>
<td>
<p>Optional network which may be used to produce feature vectors f(x) for high-dimensional observations</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>classifier_loss</code></td>
<td><code>str</code></td>
<td>
<p><code class="codehilite"><span class="err">sre</span></code> implements the algorithm suggested in Durkan et al.  2019, whereas <code class="codehilite"><span class="err">aalr</span></code> implements the algorithm suggested in Hermans et al. 2019. <code class="codehilite"><span class="err">sre</span></code> can use more than two atoms, potentially boosting performance, but does not allow for exact posterior density evaluation (only up to a normalizing constant), even when training only one round. <code class="codehilite"><span class="err">aalr</span></code> is limited to <code class="codehilite"><span class="err">num_atoms=2</span></code>, but allows for density evaluation when training for one round.</p>
</td>
<td><code>'sre'</code></td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>sbi/inference/sre/sre.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">simulator</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">prior</span><span class="p">,</span>
    <span class="n">true_observation</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">classifier</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">num_atoms</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">simulation_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">mcmc_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"slice-np"</span><span class="p">,</span>
    <span class="n">summary_net</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">classifier_loss</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"sre"</span><span class="p">,</span>
    <span class="n">retrain_from_scratch_each_round</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">summary_writer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SummaryWriter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">"""Sequential Ratio Estimation</span>

<span class="sd">    As presented in _Likelihood-free MCMC with Amortized Approximate Likelihood Ratios_ by Hermans et al., Pre-print 2019, https://arxiv.org/abs/1903.04057</span>

<span class="sd">    See NeuralInference docstring for all other arguments.</span>

<span class="sd">    Args:</span>
<span class="sd">        classifier: Binary classifier</span>
<span class="sd">        num_atoms: Number of atoms to use for classification.</span>
<span class="sd">            If -1, use all other parameters in minibatch</span>
<span class="sd">        retrain_from_scratch_each_round: whether to retrain from scratch</span>
<span class="sd">            each round</span>
<span class="sd">        summary_net: Optional network which may be used to produce feature</span>
<span class="sd">            vectors f(x) for high-dimensional observations</span>
<span class="sd">        classifier_loss: `sre` implements the algorithm suggested in Durkan et al. </span>
<span class="sd">            2019, whereas `aalr` implements the algorithm suggested in Hermans et al. 2019. `sre` can use more than two atoms, potentially boosting performance, but does not allow for exact posterior density evaluation (only up to a normalizing constant), even when training only one round. `aalr` is limited to `num_atoms=2`, but allows for density evaluation when training for one round.</span>
<span class="sd">    """</span>

    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">simulator</span><span class="p">,</span>
        <span class="n">prior</span><span class="p">,</span>
        <span class="n">true_observation</span><span class="p">,</span>
        <span class="n">simulation_batch_size</span><span class="p">,</span>
        <span class="n">device</span><span class="p">,</span>
        <span class="n">summary_writer</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_classifier_loss</span> <span class="o">=</span> <span class="n">classifier_loss</span>

    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_atoms</span><span class="p">,</span> <span class="nb">int</span><span class="p">),</span> <span class="s2">"Number of atoms must be an integer."</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_num_atoms</span> <span class="o">=</span> <span class="n">num_atoms</span>

    <span class="k">if</span> <span class="n">classifier</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">classifier</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">classifier_nn</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="s2">"resnet"</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_prior</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_true_observation</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># create posterior object which can sample()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_neural_posterior</span> <span class="o">=</span> <span class="n">Posterior</span><span class="p">(</span>
        <span class="n">algorithm_family</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_classifier_loss</span><span class="p">,</span>
        <span class="n">neural_net</span><span class="o">=</span><span class="n">classifier</span><span class="p">,</span>
        <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span>
        <span class="n">context</span><span class="o">=</span><span class="n">true_observation</span><span class="p">,</span>
        <span class="n">mcmc_method</span><span class="o">=</span><span class="n">mcmc_method</span><span class="p">,</span>
        <span class="n">get_potential_function</span><span class="o">=</span><span class="n">PotentialFunctionProvider</span><span class="p">(),</span>
    <span class="p">)</span>

    <span class="c1"># XXX why not classifier.train(True)???</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_neural_posterior</span><span class="o">.</span><span class="n">neural_net</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># We may want to summarize high-dimensional observations.</span>
    <span class="c1"># This may be either a fixed or learned transformation.</span>
    <span class="k">if</span> <span class="n">summary_net</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_summary_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_summary_net</span> <span class="o">=</span> <span class="n">summary_net</span>

    <span class="c1"># If we're retraining from scratch each round,</span>
    <span class="c1"># keep a copy of the original untrained model for reinitialization.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_retrain_from_scratch_each_round</span> <span class="o">=</span> <span class="n">retrain_from_scratch_each_round</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_retrain_from_scratch_each_round</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_untrained_classifier</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">classifier</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_untrained_classifier</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># SRE-specific summary_writer fields</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_summary</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">"mcmc_times"</span><span class="p">:</span> <span class="p">[]})</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</div>
</div>
</div>
<h2 id="models">Models<a class="headerlink" href="#models" title="Permanent link">¬∂</a></h2>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="sbi.utils.get_nn_models.posterior_nn">
<code class="highlight language-python">
sbi.utils.get_nn_models.posterior_nn<span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">embedding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hidden_features</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">mdn_num_components</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">made_num_mixture_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">made_num_blocks</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">flow_num_transforms</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> </code>
<a class="headerlink" href="#sbi.utils.get_nn_models.posterior_nn" title="Permanent link">¬∂</a></h3>
<div class="doc doc-contents first">
<p>Neural posterior density estimator</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model</code></td>
<td><code>str</code></td>
<td>
<p>Model, one of maf / mdn / made / nsf</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>prior</code></td>
<td><code>torch.distributions.Distribution</code></td>
<td>
<p>Prior distribution</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>context</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>Observation</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>embedding</code></td>
<td><code>Optional[torch.nn.Module]</code></td>
<td>
<p>Embedding network</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>hidden_features</code></td>
<td><code>int</code></td>
<td>
<p>For all, number of hidden features</p>
</td>
<td><code>50</code></td>
</tr>
<tr>
<td><code>mdn_num_components</code></td>
<td><code>int</code></td>
<td>
<p>For MDNs only, number of components</p>
</td>
<td><code>20</code></td>
</tr>
<tr>
<td><code>made_num_mixture_components</code></td>
<td><code>int</code></td>
<td>
<p>For MADEs only, number of mixture components</p>
</td>
<td><code>10</code></td>
</tr>
<tr>
<td><code>made_num_blocks</code></td>
<td><code>int</code></td>
<td>
<p>For MADEs only, number of blocks</p>
</td>
<td><code>4</code></td>
</tr>
<tr>
<td><code>flow_num_transforms</code></td>
<td><code>int</code></td>
<td>
<p>For flows only, number of transforms</p>
</td>
<td><code>5</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>torch.nn.Module</code></td>
<td>
<p>Neural network</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>sbi/utils/get_nn_models.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span> 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">posterior_nn</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">prior</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Distribution</span><span class="p">,</span>
    <span class="n">context</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">hidden_features</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="n">mdn_num_components</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">made_num_mixture_components</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">made_num_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">flow_num_transforms</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">"""Neural posterior density estimator</span>

<span class="sd">    Args:</span>
<span class="sd">        model: Model, one of maf / mdn / made / nsf</span>
<span class="sd">        prior: Prior distribution</span>
<span class="sd">        context: Observation</span>
<span class="sd">        embedding: Embedding network</span>
<span class="sd">        hidden_features: For all, number of hidden features</span>
<span class="sd">        mdn_num_components: For MDNs only, number of components</span>
<span class="sd">        made_num_mixture_components: For MADEs only, number of mixture components</span>
<span class="sd">        made_num_blocks: For MADEs only, number of blocks</span>
<span class="sd">        flow_num_transforms: For flows only, number of transforms</span>

<span class="sd">    Returns:</span>
<span class="sd">        Neural network</span>
<span class="sd">    """</span>
    <span class="n">mean</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="p">(</span><span class="n">prior</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="n">prior</span><span class="o">.</span><span class="n">stddev</span><span class="p">)</span>
    <span class="n">standardizing_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">AffineTransform</span><span class="p">(</span>
        <span class="n">shift</span><span class="o">=-</span><span class="n">mean</span> <span class="o">/</span> <span class="n">std</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span> <span class="o">/</span> <span class="n">std</span>
    <span class="p">)</span>

    <span class="n">parameter_dim</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">sample</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">context</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">torchutils</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
    <span class="n">observation_dim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">context</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]])</span>

    <span class="k">if</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"mdn"</span><span class="p">:</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">MultivariateGaussianMDN</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">parameter_dim</span><span class="p">,</span>
            <span class="n">context_features</span><span class="o">=</span><span class="n">observation_dim</span><span class="p">,</span>
            <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
            <span class="n">hidden_net</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">observation_dim</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="p">),</span>
            <span class="n">num_components</span><span class="o">=</span><span class="n">mdn_num_components</span><span class="p">,</span>
            <span class="n">custom_initialization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"made"</span><span class="p">:</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">standardizing_transform</span>
        <span class="n">distribution</span> <span class="o">=</span> <span class="n">distributions_</span><span class="o">.</span><span class="n">MADEMoG</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">parameter_dim</span><span class="p">,</span>
            <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
            <span class="n">context_features</span><span class="o">=</span><span class="n">observation_dim</span><span class="p">,</span>
            <span class="n">num_blocks</span><span class="o">=</span><span class="n">made_num_blocks</span><span class="p">,</span>
            <span class="n">num_mixture_components</span><span class="o">=</span><span class="n">made_num_mixture_components</span><span class="p">,</span>
            <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
            <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">custom_initialization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">Flow</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">distribution</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"maf"</span><span class="p">:</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">MaskedAffineAutoregressiveTransform</span><span class="p">(</span>
                            <span class="n">features</span><span class="o">=</span><span class="n">parameter_dim</span><span class="p">,</span>
                            <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
                            <span class="n">context_features</span><span class="o">=</span><span class="n">observation_dim</span><span class="p">,</span>
                            <span class="n">num_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                            <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">activation</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span>
                            <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                            <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomPermutation</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">parameter_dim</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">flow_num_transforms</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>

        <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">([</span><span class="n">standardizing_transform</span><span class="p">,</span> <span class="n">transform</span><span class="p">,])</span>

        <span class="n">distribution</span> <span class="o">=</span> <span class="n">distributions_</span><span class="o">.</span><span class="n">StandardNormal</span><span class="p">((</span><span class="n">parameter_dim</span><span class="p">,))</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">Flow</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">distribution</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"nsf"</span><span class="p">:</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">PiecewiseRationalQuadraticCouplingTransform</span><span class="p">(</span>
                            <span class="n">mask</span><span class="o">=</span><span class="n">create_alternating_binary_mask</span><span class="p">(</span>
                                <span class="n">features</span><span class="o">=</span><span class="n">parameter_dim</span><span class="p">,</span> <span class="n">even</span><span class="o">=</span><span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
                            <span class="p">),</span>
                            <span class="n">transform_net_create_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">:</span> <span class="n">nets</span><span class="o">.</span><span class="n">ResidualNet</span><span class="p">(</span>
                                <span class="n">in_features</span><span class="o">=</span><span class="n">in_features</span><span class="p">,</span>
                                <span class="n">out_features</span><span class="o">=</span><span class="n">out_features</span><span class="p">,</span>
                                <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
                                <span class="n">context_features</span><span class="o">=</span><span class="n">observation_dim</span><span class="p">,</span>
                                <span class="n">num_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                <span class="n">activation</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
                                <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="p">),</span>
                            <span class="n">num_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                            <span class="n">tails</span><span class="o">=</span><span class="s2">"linear"</span><span class="p">,</span>
                            <span class="n">tail_bound</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span>
                            <span class="n">apply_unconditional_transform</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">LULinear</span><span class="p">(</span><span class="n">parameter_dim</span><span class="p">,</span> <span class="n">identity_init</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">flow_num_transforms</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>

        <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">([</span><span class="n">standardizing_transform</span><span class="p">,</span> <span class="n">transform</span><span class="p">,])</span>

        <span class="n">distribution</span> <span class="o">=</span> <span class="n">distributions_</span><span class="o">.</span><span class="n">StandardNormal</span><span class="p">((</span><span class="n">parameter_dim</span><span class="p">,))</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">Flow</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">distribution</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span>

    <span class="k">return</span> <span class="n">neural_net</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="sbi.utils.get_nn_models.likelihood_nn">
<code class="highlight language-python">
sbi.utils.get_nn_models.likelihood_nn<span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">embedding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hidden_features</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">mdn_num_components</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">made_num_mixture_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">made_num_blocks</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">flow_num_transforms</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> </code>
<a class="headerlink" href="#sbi.utils.get_nn_models.likelihood_nn" title="Permanent link">¬∂</a></h3>
<div class="doc doc-contents first">
<p>Neural likelihood density estimator</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model</code></td>
<td><code>str</code></td>
<td>
<p>Model, one of maf / mdn / made / nsf</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>prior</code></td>
<td><code>torch.distributions.Distribution</code></td>
<td>
<p>Prior distribution</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>context</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>Observation</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>embedding</code></td>
<td><code>Optional[torch.nn.Module]</code></td>
<td>
<p>Embedding network</p>
</td>
<td><code>None</code></td>
</tr>
<tr>
<td><code>hidden_features</code></td>
<td><code>int</code></td>
<td>
<p>For all, number of hidden features</p>
</td>
<td><code>50</code></td>
</tr>
<tr>
<td><code>mdn_num_components</code></td>
<td><code>int</code></td>
<td>
<p>For MDNs only, number of components</p>
</td>
<td><code>20</code></td>
</tr>
<tr>
<td><code>made_num_mixture_components</code></td>
<td><code>int</code></td>
<td>
<p>For MADEs only, number of mixture components</p>
</td>
<td><code>10</code></td>
</tr>
<tr>
<td><code>made_num_blocks</code></td>
<td><code>int</code></td>
<td>
<p>For MADEs only, number of blocks</p>
</td>
<td><code>4</code></td>
</tr>
<tr>
<td><code>flow_num_transforms</code></td>
<td><code>int</code></td>
<td>
<p>For flows only, number of transforms</p>
</td>
<td><code>5</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>torch.nn.Module</code></td>
<td>
<p>Neural network</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>sbi/utils/get_nn_models.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
244
245
246
247
248
249
250
251
252
253
254
255
256
257
258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">likelihood_nn</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">prior</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Distribution</span><span class="p">,</span>
    <span class="n">context</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">embedding</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">hidden_features</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="n">mdn_num_components</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
    <span class="n">made_num_mixture_components</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">made_num_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">flow_num_transforms</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">"""Neural likelihood density estimator</span>

<span class="sd">    Args:</span>
<span class="sd">        model: Model, one of maf / mdn / made / nsf</span>
<span class="sd">        prior: Prior distribution</span>
<span class="sd">        context: Observation</span>
<span class="sd">        embedding: Embedding network</span>
<span class="sd">        hidden_features: For all, number of hidden features</span>
<span class="sd">        mdn_num_components: For MDNs only, number of components</span>
<span class="sd">        made_num_mixture_components: For MADEs only, number of mixture components</span>
<span class="sd">        made_num_blocks: For MADEs only, number of blocks</span>
<span class="sd">        flow_num_transforms: For flows only, number of transforms</span>

<span class="sd">    Returns:</span>
<span class="sd">        Neural network</span>
<span class="sd">    """</span>
    <span class="n">parameter_dim</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">sample</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">observation_dim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">context</span><span class="o">.</span><span class="n">shape</span><span class="p">])</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">observation_dim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">context</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"mdn"</span><span class="p">:</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">MultivariateGaussianMDN</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">observation_dim</span><span class="p">,</span>
            <span class="n">context_features</span><span class="o">=</span><span class="n">parameter_dim</span><span class="p">,</span>
            <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
            <span class="n">hidden_net</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">parameter_dim</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">),</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="p">),</span>
            <span class="n">num_components</span><span class="o">=</span><span class="n">mdn_num_components</span><span class="p">,</span>
            <span class="n">custom_initialization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"made"</span><span class="p">:</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">MixtureOfGaussiansMADE</span><span class="p">(</span>
            <span class="n">features</span><span class="o">=</span><span class="n">observation_dim</span><span class="p">,</span>
            <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
            <span class="n">context_features</span><span class="o">=</span><span class="n">parameter_dim</span><span class="p">,</span>
            <span class="n">num_blocks</span><span class="o">=</span><span class="n">made_num_blocks</span><span class="p">,</span>
            <span class="n">num_mixture_components</span><span class="o">=</span><span class="n">made_num_mixture_components</span><span class="p">,</span>
            <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
            <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">custom_initialization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"maf"</span><span class="p">:</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">MaskedAffineAutoregressiveTransform</span><span class="p">(</span>
                            <span class="n">features</span><span class="o">=</span><span class="n">observation_dim</span><span class="p">,</span>
                            <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
                            <span class="n">context_features</span><span class="o">=</span><span class="n">parameter_dim</span><span class="p">,</span>
                            <span class="n">num_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                            <span class="n">use_residual_blocks</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">random_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">activation</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span>
                            <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                            <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomPermutation</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">observation_dim</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">flow_num_transforms</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="n">distribution</span> <span class="o">=</span> <span class="n">distributions_</span><span class="o">.</span><span class="n">StandardNormal</span><span class="p">((</span><span class="n">observation_dim</span><span class="p">,))</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">Flow</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">distribution</span><span class="p">,</span> <span class="n">embedding</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"nsf"</span><span class="p">:</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">transforms</span><span class="o">.</span><span class="n">CompositeTransform</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">PiecewiseRationalQuadraticCouplingTransform</span><span class="p">(</span>
                            <span class="n">mask</span><span class="o">=</span><span class="n">create_alternating_binary_mask</span><span class="p">(</span>
                                <span class="n">features</span><span class="o">=</span><span class="n">observation_dim</span><span class="p">,</span> <span class="n">even</span><span class="o">=</span><span class="p">(</span><span class="n">i</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
                            <span class="p">),</span>
                            <span class="n">transform_net_create_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">:</span> <span class="n">nets</span><span class="o">.</span><span class="n">ResidualNet</span><span class="p">(</span>
                                <span class="n">in_features</span><span class="o">=</span><span class="n">in_features</span><span class="p">,</span>
                                <span class="n">out_features</span><span class="o">=</span><span class="n">out_features</span><span class="p">,</span>
                                <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
                                <span class="n">context_features</span><span class="o">=</span><span class="n">parameter_dim</span><span class="p">,</span>
                                <span class="n">num_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                <span class="n">activation</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
                                <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="p">),</span>
                            <span class="n">num_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                            <span class="n">tails</span><span class="o">=</span><span class="s2">"linear"</span><span class="p">,</span>
                            <span class="n">tail_bound</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span>
                            <span class="n">apply_unconditional_transform</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="p">),</span>
                        <span class="n">transforms</span><span class="o">.</span><span class="n">LULinear</span><span class="p">(</span><span class="n">observation_dim</span><span class="p">,</span> <span class="n">identity_init</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">flow_num_transforms</span><span class="p">)</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="n">distribution</span> <span class="o">=</span> <span class="n">distributions_</span><span class="o">.</span><span class="n">StandardNormal</span><span class="p">((</span><span class="n">observation_dim</span><span class="p">,))</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">flows</span><span class="o">.</span><span class="n">Flow</span><span class="p">(</span><span class="n">transform</span><span class="p">,</span> <span class="n">distribution</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span>

    <span class="k">return</span> <span class="n">neural_net</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
<div class="doc doc-object doc-function">
<h3 class="doc doc-heading" id="sbi.utils.get_nn_models.classifier_nn">
<code class="highlight language-python">
sbi.utils.get_nn_models.classifier_nn<span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">hidden_features</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span> </code>
<a class="headerlink" href="#sbi.utils.get_nn_models.classifier_nn" title="Permanent link">¬∂</a></h3>
<div class="doc doc-contents first">
<p>Neural classifier</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>model</code></td>
<td><code></code></td>
<td>
<p>Model, one of linear / mlp / resnet</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>prior</code></td>
<td><code>torch.distributions.Distribution</code></td>
<td>
<p>Prior distribution</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>context</code></td>
<td><code>torch.Tensor</code></td>
<td>
<p>Observation</p>
</td>
<td><em>required</em></td>
</tr>
<tr>
<td><code>hidden_features</code></td>
<td><code>int</code></td>
<td>
<p>For all, number of hidden features</p>
</td>
<td><code>50</code></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>torch.nn.Module</code></td>
<td>
<p>Neural network</p>
</td>
</tr>
</tbody>
</table>
<details class="quote">
<summary>Source code in <code>sbi/utils/get_nn_models.py</code></summary>
<table class="highlighttable">
<tr>
<td class="linenos">
<div class="linenodiv">
<pre><span></span>292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323
324
325
326
327
328
329
330
331
332
333
334
335
336
337
338
339
340
341
342</pre>
</div>
</td>
<td class="code">
<div class="highlight">
<pre><span></span><code><span class="k">def</span> <span class="nf">classifier_nn</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">prior</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Distribution</span><span class="p">,</span>
    <span class="n">context</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">hidden_features</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">"""Neural classifier</span>

<span class="sd">    Args:</span>
<span class="sd">        model: Model, one of linear / mlp / resnet</span>
<span class="sd">        prior: Prior distribution</span>
<span class="sd">        context: Observation</span>
<span class="sd">        hidden_features: For all, number of hidden features</span>

<span class="sd">    Returns:</span>
<span class="sd">        Neural network</span>
<span class="sd">    """</span>
    <span class="n">parameter_dim</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">sample</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">torchutils</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
    <span class="n">observation_dim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">context</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]])</span>

    <span class="k">if</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"linear"</span><span class="p">:</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">parameter_dim</span> <span class="o">+</span> <span class="n">observation_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"mlp"</span><span class="p">:</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">parameter_dim</span> <span class="o">+</span> <span class="n">observation_dim</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="n">hidden_features</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_features</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">elif</span> <span class="n">model</span> <span class="o">==</span> <span class="s2">"resnet"</span><span class="p">:</span>
        <span class="n">neural_net</span> <span class="o">=</span> <span class="n">nets</span><span class="o">.</span><span class="n">ResidualNet</span><span class="p">(</span>
            <span class="n">in_features</span><span class="o">=</span><span class="n">parameter_dim</span> <span class="o">+</span> <span class="n">observation_dim</span><span class="p">,</span>
            <span class="n">out_features</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">hidden_features</span><span class="o">=</span><span class="n">hidden_features</span><span class="p">,</span>
            <span class="n">context_features</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">num_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
            <span class="n">dropout_probability</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">use_batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"'model' must be one of ['linear', 'mlp', 'resnet']."</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">neural_net</span>
</code></pre>
</div>
</td>
</tr>
</table>
</details>
</div>
</div>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<div class="md-footer-nav">
<nav class="md-footer-nav__inner md-grid">
<a class="md-flex md-footer-nav__link md-footer-nav__link--prev" href="../install/" rel="prev" title="Installation">
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
</div>
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  Previous
                </span>
                Installation
              </span>
</div>
</a>
<a class="md-flex md-footer-nav__link md-footer-nav__link--next" href="../credits/" rel="next" title="Credits">
<div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
<span class="md-flex__ellipsis">
<span class="md-footer-nav__direction">
                  Next
                </span>
                Credits
              </span>
</div>
<div class="md-flex__cell md-flex__cell--shrink">
<i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
</div>
</a>
</nav>
</div>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org" rel="noopener" target="_blank">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
          Material for MkDocs</a>
</div>
<div class="md-footer-social">
<link href="../assets/fonts/font-awesome.css" rel="stylesheet"/>
<a class="md-footer-social__link fa fa-github" href="https://github.com/mackelab/sbi" rel="noopener" target="_blank" title="github"></a>
</div>
</div>
</div>
</footer>
</div>
<script src="../assets/javascripts/application.c33a9706.js"></script>
<script>app.initialize({version:"1.1",url:{base:".."}})</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>